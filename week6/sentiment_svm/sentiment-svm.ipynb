{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with support vector machines\n",
    "\n",
    "In this notebook, we will revisit a learning task that we encountered earlier in the course: predicting the *sentiment* (positive or negative) of a single sentence taken from a review of a movie, restaurant, or product. The data set consists of 3000 labeled sentences, which we divide into a training set of size 2500 and a test set of size 500. Previously we found a logistic regression classifier. Today we will use a support vector machine.\n",
    "\n",
    "Before starting on this notebook, make sure the folder `sentiment_labelled_sentences` (containing the data file `full_set.txt`) is in the same directory. Recall that the data can be downloaded from https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing the data\n",
    " \n",
    "Here we follow exactly the same steps as we did earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (2500, 4500)\n",
      "test data:  (500, 4500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Read in the data set.\n",
    "with open(\"sentiment_labelled_sentences/full_set.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "## Remove leading and trailing white space\n",
    "content = [x.strip() for x in content]\n",
    "\n",
    "## Separate the sentences from the labels\n",
    "sentences = [x.split(\"\\t\")[0] for x in content]\n",
    "labels = [x.split(\"\\t\")[1] for x in content]\n",
    "\n",
    "## Transform the labels from '0 v.s. 1' to '-1 v.s. 1'\n",
    "y = np.array(labels, dtype='int8')\n",
    "y = 2*y - 1\n",
    "\n",
    "## full_remove takes a string x and a list of characters removal_list \n",
    "## returns x with all the characters in removal_list replaced by ' '\n",
    "def full_remove(x, removal_list):\n",
    "    for w in removal_list:\n",
    "        x = x.replace(w, ' ')\n",
    "    return x\n",
    "\n",
    "## Remove digits\n",
    "digits = [str(x) for x in range(10)]\n",
    "digit_less = [full_remove(x, digits) for x in sentences]\n",
    "\n",
    "## Remove punctuation\n",
    "punc_less = [full_remove(x, list(string.punctuation)) for x in digit_less]\n",
    "\n",
    "## Make everything lower-case\n",
    "sents_lower = [x.lower() for x in punc_less]\n",
    "\n",
    "## Define our stop words\n",
    "stop_set = set(['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from'])\n",
    "\n",
    "## Remove stop words\n",
    "sents_split = [x.split() for x in sents_lower]\n",
    "sents_processed = [\" \".join(list(filter(lambda a: a not in stop_set, x))) for x in sents_split]\n",
    "\n",
    "## Transform to bag of words representation.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 4500)\n",
    "data_features = vectorizer.fit_transform(sents_processed)\n",
    "\n",
    "## Append '1' to the end of each vector.\n",
    "data_mat = data_features.toarray()\n",
    "\n",
    "## Split the data into testing and training sets\n",
    "np.random.seed(0)\n",
    "test_inds = np.append(np.random.choice((np.where(y==-1))[0], 250, replace=False), np.random.choice((np.where(y==1))[0], 250, replace=False))\n",
    "train_inds = list(set(range(len(labels))) - set(test_inds))\n",
    "\n",
    "train_data = data_mat[train_inds,]\n",
    "train_labels = y[train_inds]\n",
    "\n",
    "test_data = data_mat[test_inds,]\n",
    "test_labels = y[test_inds]\n",
    "\n",
    "print(\"train data: \", train_data.shape)\n",
    "print(\"test data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitting a support vector machine to the data\n",
    "\n",
    "In support vector machines, we are given a set of examples $(x_1, y_1), \\ldots, (x_n, y_n)$ and we want to find a weight vector $w \\in \\mathbb{R}^d$ that solves the following optimization problem:\n",
    "\n",
    "$$ \\min_{w \\in \\mathbb{R}^d} \\| w \\|^2 + C \\sum_{i=1}^n \\xi_i $$\n",
    "$$ \\text{subject to } y_i \\langle w, x_i \\rangle \\geq 1 - \\xi_i \\text{ for all } i=1,\\ldots, n$$\n",
    "\n",
    "`scikit-learn` provides an SVM solver that we will use. The following routine takes as input the constant `C` (from the above optimization problem) and returns the training and test error of the resulting SVM model. It is invoked as follows:\n",
    "\n",
    "* `training_error, test_error = fit_classifier(C)`\n",
    "\n",
    "The default value for parameter `C` is 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "def fit_classifier(C_value=1.0):\n",
    "    clf = svm.LinearSVC(C=C_value, loss='hinge')\n",
    "    clf.fit(train_data,train_labels)\n",
    "    ## Get predictions on training data\n",
    "    train_preds = clf.predict(train_data)\n",
    "    train_error = float(np.sum((train_preds > 0.0) != (train_labels > 0.0)))/len(train_labels)\n",
    "    ## Get predictions on test data\n",
    "    test_preds = clf.predict(test_data)\n",
    "    test_error = float(np.sum((test_preds > 0.0) != (test_labels > 0.0)))/len(test_labels)\n",
    "    ##\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 0.01: train 0.215 test 0.250\n",
      "Error rate for C = 0.10: train 0.074 test 0.174\n",
      "Error rate for C = 1.00: train 0.011 test 0.152\n",
      "Error rate for C = 10.00: train 0.002 test 0.188\n",
      "Error rate for C = 100.00: train 0.002 test 0.198\n",
      "Error rate for C = 1000.00: train 0.003 test 0.212\n",
      "Error rate for C = 10000.00: train 0.001 test 0.208\n"
     ]
    }
   ],
   "source": [
    "cvals = [0.01,0.1,1.0,10.0,100.0,1000.0,10000.0]\n",
    "for c in cvals:\n",
    "    train_error, test_error = fit_classifier(c)\n",
    "    print (\"Error rate for C = %0.2f: train %0.3f test %0.3f\" % (c, train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluating C by k-fold cross-validation\n",
    "\n",
    "As we can see, the choice of `C` has a very significant effect on the performance of the SVM classifier. We were able to assess this because we have a separate test set. In general, however, this is a luxury we won't possess. How can we choose `C` based only on the training set?\n",
    "\n",
    "A reasonable way to estimate the error associated with a specific value of `C` is by **`k-fold cross validation`**:\n",
    "* Partition the training set `S` into `k` equal-sized sized subsets `S_1, S_2, ..., S_k`.\n",
    "* For `i=1,2,...,k`, train a classifier with parameter `C` on `S - S_i` (all the training data except `S_i`) and test it on `S_i` to get error estimate `e_i`.\n",
    "* Average the errors: `(e_1 + ... + e_k)/k`\n",
    "\n",
    "The following procedure, **cross_validation_error**, does exactly this. It takes as input:\n",
    "* the training set `x,y`\n",
    "* the value of `C` to be evaluated\n",
    "* the integer `k`\n",
    "\n",
    "and it returns the estimated error of the classifier for that particular setting of `C`. <font color=\"magenta\">Look over the code carefully to understand exactly what it is doing.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_error(x,y,C_value,k):\n",
    "    n = len(y)\n",
    "    ## Randomly shuffle indices\n",
    "    indices = np.random.permutation(n)\n",
    "    \n",
    "    ## Initialize error\n",
    "    err = 0.0\n",
    "    \n",
    "    ## Iterate over partitions\n",
    "    for i in range(k):\n",
    "        ## Partition indices\n",
    "        test_indices = indices[int(i*(n/k)):int((i+1)*(n/k) - 1)]\n",
    "        train_indices = np.setdiff1d(indices, test_indices)\n",
    "        \n",
    "        ## Train classifier with parameter c\n",
    "        clf = svm.LinearSVC(C=C_value, loss='hinge')\n",
    "        clf.fit(x[train_indices], y[train_indices])\n",
    "        \n",
    "        ## Get predictions on test partition\n",
    "        preds = clf.predict(x[test_indices])\n",
    "        \n",
    "        ## Compute error\n",
    "        err += float(np.sum((preds > 0.0) != (y[test_indices] > 0.0)))/len(test_indices)\n",
    "        \n",
    "    return err/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Picking a value of C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure **cross_validation_error** (above) evaluates a single candidate value of `C`. We need to use it repeatedly to identify a good `C`. \n",
    "\n",
    "<font color=\"magenta\">**For you to do:**</font> Write a function to choose `C`. It will be invoked as follows:\n",
    "\n",
    "* `c, err = choose_parameter(x,y,k)`\n",
    "\n",
    "where\n",
    "* `x,y` is the training data\n",
    "* `k` is the number of folds of cross-validation\n",
    "* `c` is chosen value of the parameter `C`\n",
    "* `err` is the cross-validation error estimate at `c`\n",
    "\n",
    "<font color=\"magenta\">Note:</font> This is a tricky business because a priori, even the order of magnitude of `C` is unknown. Should it be 0.0001 or 10000? You might want to think about trying multiple values that are arranged in a geometric progression (such as powers of ten). *In addition to returning a specific value of `C`, your function should **plot** the cross-validation errors for all the values of `C` it tried out (possibly using a log-scale for the `C`-axis).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_parameter(x,y,k):\n",
    "    # candidate values of C\n",
    "    C = np.geomspace(0.01, 10, 20)\n",
    "    \n",
    "    # cross-validated errors\n",
    "    err = np.zeros_like(C)\n",
    "    \n",
    "    # run svm for each C\n",
    "    for index, C_current in np.ndenumerate(C):\n",
    "        err[index] = cross_validation_error(x, y, C_current, k)\n",
    "        \n",
    "    # choose C with lowest error\n",
    "    best_index = np.argmin(err)\n",
    "    C_best = C[best_index]\n",
    "    err_best = err[best_index]\n",
    "    \n",
    "    # plot results\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(C, err)\n",
    "    ax.set_xscale(\"log\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return C_best, err_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out your routine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1141c74e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice of C:  0.12742749857031335\n",
      "Cross-validation error estimate:  0.18353413654618472\n",
      "Test error:  0.156\n"
     ]
    }
   ],
   "source": [
    "c, err = choose_parameter(train_data, train_labels, 10)\n",
    "print(\"Choice of C: \", c)\n",
    "print(\"Cross-validation error estimate: \", err)\n",
    "## Train it and test it\n",
    "clf = svm.LinearSVC(C=c, loss='hinge')\n",
    "clf.fit(train_data, train_labels)\n",
    "preds = clf.predict(test_data)\n",
    "error = float(np.sum((preds > 0.0) != (test_labels > 0.0)))/len(test_labels)\n",
    "print(\"Test error: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**For you to ponder:**</font> How does the plot of cross-validation errors for different `C` look? Is there clearly a trough in which the returned value of `C` falls? Does the plot provide some reassurance that the choice is reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "344px",
    "left": "1px",
    "right": "20px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
